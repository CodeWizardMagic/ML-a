{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1def40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f1def40",
        "outputId": "88dc3825-0d24-451d-b8d7-19c76f293749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Environment ready\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip -q install ultralytics kagglehub scikit-learn pandas matplotlib pyyaml\n",
        "from ultralytics import YOLO\n",
        "import os, sys, glob, shutil, json, random, zipfile, yaml, pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "print(\"Environment ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433f1710",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "433f1710",
        "outputId": "1386d3c0-d9e2-4f81-95c6-f2aba01b4a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying KaggleHub download...\n",
            "Using Colab cache for faster access to the 'license-plate-dataset' dataset.\n",
            "Downloaded via KaggleHub: /kaggle/input/license-plate-dataset\n",
            "Dataset root: /kaggle/input/license-plate-dataset\n",
            "Detected 'archive' folder: /kaggle/input/license-plate-dataset/archive\n",
            "â„¹ï¸ No ZIP files found â€” data may already be extracted or provided as folders.\n",
            "Data prepared in: ./license_plate_data\n",
            "Dir listing: []\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Detect dataset location or download via KaggleHub\n",
        "base_candidates = [\n",
        "    \"/kaggle/input/license-plate-dataset\",                          # Kaggle environment\n",
        "    os.path.expanduser(\"~/.cache/kagglehub/datasets/ronakgohil/license-plate-dataset/versions/latest\")\n",
        "]\n",
        "dataset_root = None\n",
        "\n",
        "for cand in base_candidates:\n",
        "    if os.path.exists(cand):\n",
        "        dataset_root = cand\n",
        "        break\n",
        "\n",
        "if dataset_root is None:\n",
        "    print(\"Trying KaggleHub download...\")\n",
        "    import kagglehub\n",
        "    try:\n",
        "        # Ensure user is logged in (run kagglehub.login() once manually if needed)\n",
        "        path = kagglehub.dataset_download(\"ronakgohil/license-plate-dataset\")\n",
        "        dataset_root = path\n",
        "        print(\"Downloaded via KaggleHub:\", dataset_root)\n",
        "    except Exception as e:\n",
        "        print(\"Could not download via KaggleHub. Error:\", e)\n",
        "        raise SystemExit(\"Please run kagglehub.login() and ensure your Kaggle API key is configured.\")\n",
        "\n",
        "print(\"Dataset root:\", dataset_root)\n",
        "\n",
        "# Some Kaggle datasets come as a subfolder 'archive' with ZIP(s) inside.\n",
        "archive_dir = os.path.join(dataset_root, \"archive\")\n",
        "if os.path.isdir(archive_dir):\n",
        "    dataset_root = archive_dir  # we'll search zips inside\n",
        "    print(\"Detected 'archive' folder:\", dataset_root)\n",
        "\n",
        "# Create a working extraction directory\n",
        "work_dir = \"/kaggle/working/license_plate_data\" if os.path.exists(\"/kaggle/working\") else \"./license_plate_data\"\n",
        "os.makedirs(work_dir, exist_ok=True)\n",
        "\n",
        "# Unzip any zip files found under dataset_root (non-destructive re-run safe)\n",
        "zips = [os.path.join(dataset_root, f) for f in os.listdir(dataset_root) if f.lower().endswith(\".zip\")]\n",
        "if len(zips) == 0:\n",
        "    print(\"â„¹ï¸ No ZIP files found â€” data may already be extracted or provided as folders.\")\n",
        "else:\n",
        "    for z in zips:\n",
        "        print(\"Extracting:\", z)\n",
        "        with zipfile.ZipFile(z, 'r') as zip_ref:\n",
        "            zip_ref.extractall(work_dir)\n",
        "\n",
        "print(\"Data prepared in:\", work_dir)\n",
        "print(\"Dir listing:\", os.listdir(work_dir))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Robust dataset resolver for Colab/Kaggle/local =====\n",
        "import os, sys, shutil, zipfile, glob\n",
        "\n",
        "def resolve_dataset_root():\n",
        "    # 1) Ğ¢Ğ¸Ğ¿Ğ¾Ğ²Ñ‹Ğµ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ñ‹ (Ğ²Ğ´Ñ€ÑƒĞ³ Ñ‚Ñ‹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ½Ğ° Kaggle)\n",
        "    candidates = [\n",
        "        \"/kaggle/input/license-plate-dataset\",\n",
        "        \"/content/kaggle/input/license-plate-dataset\",\n",
        "        os.path.expanduser(\"~/.cache/kagglehub/datasets/ronakgohil/license-plate-dataset/versions/latest\"),\n",
        "    ]\n",
        "\n",
        "    for c in candidates:\n",
        "        if os.path.exists(c):\n",
        "            print(\"Found dataset at:\", c)\n",
        "            return c\n",
        "\n",
        "    # 2) Ğ•ÑĞ»Ğ¸ Ğ½Ğ¸ Ğ¾Ğ´Ğ¸Ğ½ Ğ¿ÑƒÑ‚ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ â€” ĞºĞ°Ñ‡Ğ°ĞµĞ¼ KaggleHub\n",
        "    print(\"None of the default paths exist. Trying KaggleHub download...\")\n",
        "    try:\n",
        "        import kagglehub\n",
        "    except ImportError:\n",
        "        !pip -q install kagglehub\n",
        "        import kagglehub\n",
        "\n",
        "    try:\n",
        "        # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ»Ğ¾Ğ³Ğ¸Ğ½Ğ¸Ğ»ÑÑ Ñ€Ğ°Ğ½ÑŒÑˆĞµ â€” Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ğ´Ğ¸Ğ½ Ñ€Ğ°Ğ· Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ:\n",
        "        # kagglehub.login()\n",
        "        path = kagglehub.dataset_download(\"ronakgohil/license-plate-dataset\")\n",
        "        print(\"Downloaded via KaggleHub:\", path)\n",
        "        return path\n",
        "    except Exception as e:\n",
        "        print(\"KaggleHub download failed:\", e)\n",
        "        raise SystemExit(\"Configure Kaggle API: run kagglehub.login() once, then rerun this cell.\")\n",
        "\n",
        "def recursive_unzip_or_copy(dataset_root, work_dir):\n",
        "    os.makedirs(work_dir, exist_ok=True)\n",
        "    # ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ archive â€” ÑƒĞ³Ğ»ÑƒĞ±Ğ¸Ğ¼ÑÑ\n",
        "    archive_dir = os.path.join(dataset_root, \"archive\")\n",
        "    if os.path.isdir(archive_dir):\n",
        "        dataset_root = archive_dir\n",
        "\n",
        "    # ÑĞ¾Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ²ÑĞµ ZIP Ñ€ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ğ¾\n",
        "    zip_paths = []\n",
        "    for r, d, f in os.walk(dataset_root):\n",
        "        for name in f:\n",
        "            if name.lower().endswith(\".zip\"):\n",
        "                zip_paths.append(os.path.join(r, name))\n",
        "\n",
        "    if zip_paths:\n",
        "        print(f\"Found {len(zip_paths)} zip(s). Extracting into:\", work_dir)\n",
        "        for z in zip_paths:\n",
        "            print(\"  ->\", z)\n",
        "            with zipfile.ZipFile(z, 'r') as zf:\n",
        "                zf.extractall(work_dir)\n",
        "    else:\n",
        "        print(\"â„¹No zips found. Copying dataset_root -> work_dir\")\n",
        "        # ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑÑ‘ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ (read-only -> writable)\n",
        "        for item in os.listdir(dataset_root):\n",
        "            src = os.path.join(dataset_root, item)\n",
        "            dst = os.path.join(work_dir, item)\n",
        "            if os.path.isdir(src):\n",
        "                shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "            else:\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "    # Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°\n",
        "    print(\"work_dir content (top 2 levels):\")\n",
        "    depth0 = work_dir.count(os.sep)\n",
        "    for r, d, f in os.walk(work_dir):\n",
        "        depth = r.count(os.sep) - depth0\n",
        "        print(r, \"->\", len(f), \"files\")\n",
        "        if depth >= 1:\n",
        "            continue\n",
        "\n",
        "def assert_images_exist(work_dir):\n",
        "    img_exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\")\n",
        "    img_paths = []\n",
        "    for r, d, f in os.walk(work_dir):\n",
        "        for name in f:\n",
        "            if name.lower().endswith(img_exts):\n",
        "                img_paths.append(os.path.join(r, name))\n",
        "    print(\"Found images:\", len(img_paths))\n",
        "    if len(img_paths) == 0:\n",
        "        # Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ°Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°\n",
        "        print(\"Listing top-level dirs/files under work_dir for inspection:\")\n",
        "        for item in os.listdir(work_dir):\n",
        "            print(\" -\", item)\n",
        "        raise RuntimeError(\"No images found after extraction. The dataset may have a different nested structure. Inspect the printed tree.\")\n",
        "\n",
        "# ---------- Run ----------\n",
        "dataset_root = resolve_dataset_root()\n",
        "\n",
        "work_dir = \"/kaggle/working/license_plate_data\" if os.path.exists(\"/kaggle/working\") else \"./license_plate_data\"\n",
        "recursive_unzip_or_copy(dataset_root, work_dir)\n",
        "assert_images_exist(work_dir)\n",
        "\n",
        "print(\"Dataset ready at:\", work_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enPwR2HQ-kG8",
        "outputId": "12a06eac-9b7d-4f63-9a47-3d3d24594028"
      },
      "id": "enPwR2HQ-kG8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found dataset at: /kaggle/input/license-plate-dataset\n",
            "â„¹No zips found. Copying dataset_root -> work_dir\n",
            "work_dir content (top 2 levels):\n",
            "./license_plate_data -> 2 files\n",
            "./license_plate_data/images -> 0 files\n",
            "./license_plate_data/images/train -> 1526 files\n",
            "./license_plate_data/images/val -> 169 files\n",
            "./license_plate_data/labels -> 0 files\n",
            "./license_plate_data/labels/train -> 1526 files\n",
            "./license_plate_data/labels/val -> 169 files\n",
            "Found images: 1695\n",
            "Dataset ready at: ./license_plate_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4585019c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4585019c",
        "outputId": "00c656c8-86ab-4423-c210-3f5660dfa608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images dir: ./license_plate_data/images\n",
            "Labels dir: ./license_plate_data/labels\n",
            "Subfolders in images: ['train', 'val', 'test']\n",
            "Wrote data.yaml -> ./license_plate_data/data.yaml\n",
            "train: ./license_plate_data/images/train\n",
            "val: ./license_plate_data/images/val\n",
            "test: ./license_plate_data/images/test\n",
            "nc: 1\n",
            "names:\n",
            "- license_plate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def find_yolo_dirs(root):\n",
        "    # Check for standard YOLO structure\n",
        "    images_dir = None\n",
        "    labels_dir = None\n",
        "    for candidate in [\"images\", \"Images\"]:\n",
        "        p = os.path.join(root, candidate)\n",
        "        if os.path.isdir(p):\n",
        "            images_dir = p\n",
        "            break\n",
        "    for candidate in [\"labels\", \"Labels\"]:\n",
        "        p = os.path.join(root, candidate)\n",
        "        if os.path.isdir(p):\n",
        "            labels_dir = p\n",
        "            break\n",
        "    return images_dir, labels_dir\n",
        "\n",
        "def has_split(images_dir):\n",
        "    if images_dir is None:\n",
        "        return False\n",
        "    sub = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir,d))]\n",
        "    return set(sub) >= set([\"train\",\"val\"]) or set(sub) >= set([\"train\",\"valid\"])\n",
        "\n",
        "def ensure_split(root):\n",
        "    # Try to find an existing YOLO structure\n",
        "    images_dir, labels_dir = find_yolo_dirs(root)\n",
        "    if images_dir and has_split(images_dir):\n",
        "        # Normalize \"valid\" -> \"val\"\n",
        "        for old in [\"valid\", \"validation\"]:\n",
        "            oldp = os.path.join(images_dir, old)\n",
        "            if os.path.isdir(oldp):\n",
        "                os.rename(oldp, os.path.join(images_dir, \"val\"))\n",
        "            oldp = os.path.join(os.path.dirname(images_dir), \"labels\", old)\n",
        "            if os.path.isdir(oldp):\n",
        "                os.rename(oldp, os.path.join(os.path.dirname(images_dir), \"labels\", \"val\"))\n",
        "        # If test not present, make small test from val\n",
        "        test_dir = os.path.join(images_dir, \"test\")\n",
        "        if not os.path.isdir(test_dir):\n",
        "            os.makedirs(test_dir, exist_ok=True)\n",
        "            labels_test = os.path.join(os.path.dirname(images_dir), \"labels\", \"test\")\n",
        "            os.makedirs(labels_test, exist_ok=True)\n",
        "            val_images = glob.glob(os.path.join(images_dir, \"val\", \"*.*\"))\n",
        "            move_count = max(1, len(val_images)//10)\n",
        "            for p in random.sample(val_images, min(move_count, len(val_images))):\n",
        "                base = os.path.basename(p)\n",
        "                # Move image\n",
        "                shutil.move(p, os.path.join(test_dir, base))\n",
        "                # Move label if exists\n",
        "                label_src = os.path.join(os.path.dirname(images_dir), \"labels\", \"val\", os.path.splitext(base)[0] + \".txt\")\n",
        "                label_dst = os.path.join(os.path.dirname(images_dir), \"labels\", \"test\", os.path.splitext(base)[0] + \".txt\")\n",
        "                if os.path.exists(label_src):\n",
        "                    shutil.move(label_src, label_dst)\n",
        "        return images_dir, os.path.join(os.path.dirname(images_dir), \"labels\")\n",
        "\n",
        "    # If no split, attempt to create from flat structure\n",
        "    flat_images = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        for fn in filenames:\n",
        "            if fn.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\")):\n",
        "                flat_images.append(os.path.join(dirpath, fn))\n",
        "    if len(flat_images) == 0:\n",
        "        raise RuntimeError(\"No images found to prepare a split. Please check dataset content.\")\n",
        "\n",
        "    # Create YOLO directories\n",
        "    img_root = os.path.join(root, \"images\"); lbl_root = os.path.join(root, \"labels\")\n",
        "    for subset in [\"train\",\"val\",\"test\"]:\n",
        "        os.makedirs(os.path.join(img_root, subset), exist_ok=True)\n",
        "        os.makedirs(os.path.join(lbl_root, subset), exist_ok=True)\n",
        "\n",
        "    # Try to find matching labels (YOLO .txt alongside image names)\n",
        "    pairs = []\n",
        "    for img in flat_images:\n",
        "        base = os.path.splitext(os.path.basename(img))[0]\n",
        "        label_candidates = glob.glob(os.path.join(os.path.dirname(img), base + \".txt\"))\n",
        "        label = label_candidates[0] if label_candidates else None\n",
        "        pairs.append((img, label))\n",
        "\n",
        "    # Split 70/20/10\n",
        "    img_paths = [p for p,_ in pairs]\n",
        "    train_imgs, tmp = train_test_split(img_paths, test_size=0.3, random_state=42)\n",
        "    val_imgs, test_imgs = train_test_split(tmp, test_size=(1/3), random_state=42)  # 0.2/0.1\n",
        "\n",
        "    def move_pairs(img_list, subset):\n",
        "        for img in img_list:\n",
        "            base = os.path.splitext(os.path.basename(img))[0]\n",
        "            dst_img = os.path.join(img_root, subset, os.path.basename(img))\n",
        "            shutil.copy2(img, dst_img)\n",
        "            # Move/copy label if found\n",
        "            cand = glob.glob(os.path.join(os.path.dirname(img), base + \".txt\"))\n",
        "            if cand:\n",
        "                shutil.copy2(cand[0], os.path.join(lbl_root, subset, base + \".txt\"))\n",
        "\n",
        "    move_pairs(train_imgs, \"train\")\n",
        "    move_pairs(val_imgs,   \"val\")\n",
        "    move_pairs(test_imgs,  \"test\")\n",
        "    return img_root, lbl_root\n",
        "\n",
        "# Prepare split (re-entrant safe)\n",
        "images_dir, labels_dir = ensure_split(work_dir)\n",
        "print(\"Images dir:\", images_dir)\n",
        "print(\"Labels dir:\", labels_dir)\n",
        "print(\"Subfolders in images:\", os.listdir(images_dir))\n",
        "\n",
        "# Create a minimal data.yaml (1 class: license_plate). Adjust if your dataset has multiple classes.\n",
        "data_yaml_path = os.path.join(work_dir, \"data.yaml\")\n",
        "data_cfg = {\n",
        "    \"train\": os.path.join(images_dir, \"train\"),\n",
        "    \"val\":   os.path.join(images_dir, \"val\"),\n",
        "    \"test\":  os.path.join(images_dir, \"test\"),\n",
        "    \"nc\":    1,\n",
        "    \"names\": [\"license_plate\"]\n",
        "}\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f, sort_keys=False)\n",
        "print(\"Wrote data.yaml ->\", data_yaml_path)\n",
        "print(open(data_yaml_path).read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb4512a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcb4512a",
        "outputId": "210a1521-b9ad-4cf5-9d19-a78e83b55773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 92.9MB/s 0.1s\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/license_plate_data/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=single_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_lp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_lp/single_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 19.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 85.4MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1078.6Â±898.8 MB/s, size: 85.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/license_plate_data/labels/train... 1526 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1526/1526 1.5Kit/s 1.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/license_plate_data/images/train/car-wbs-MH03AR5549_00000.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/license_plate_data/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 568.5Â±64.9 MB/s, size: 189.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/labels/val... 153 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 153/153 1.5Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/license_plate_data/labels/val.cache\n",
            "Plotting labels to /content/runs_lp/single_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_lp/single_run\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.08G     0.9886      1.886      1.024          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.3it/s 29.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.7it/s 3.0s\n",
            "                   all        153        153      0.977      0.882      0.972      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      2.71G      0.928       1.07     0.9691         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        153        153      0.972      0.899      0.983      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      2.73G     0.9311     0.8592     0.9828         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.4it/s 1.5s\n",
            "                   all        153        153      0.939      0.901      0.961      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      2.75G     0.9322     0.7406     0.9858         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        153        153      0.973      0.947      0.981      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      2.77G     0.8491     0.6619     0.9583         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.7it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.5it/s 2.0s\n",
            "                   all        153        153      0.981      0.908      0.975      0.745\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      2.78G     0.8525     0.6159     0.9539          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.2it/s 2.3s\n",
            "                   all        153        153      0.987      0.966       0.99      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20       2.8G     0.8204      0.579      0.951         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.8it/s 1.8s\n",
            "                   all        153        153       0.98      0.949      0.991       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      2.81G     0.8143     0.5555     0.9431         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all        153        153      0.987      0.965      0.987      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      2.83G     0.7867     0.5342     0.9363         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.8it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.2it/s 1.6s\n",
            "                   all        153        153      0.971      0.961      0.989      0.808\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      2.85G     0.7618     0.5049     0.9225          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.9it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all        153        153      0.993      0.987      0.989      0.819\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      2.86G     0.7534     0.4826      0.911          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 3.6it/s 26.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.5it/s 1.4s\n",
            "                   all        153        153      0.993      0.979      0.994      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      2.88G     0.7149      0.474     0.9084          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.1it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.7it/s 1.9s\n",
            "                   all        153        153      0.981      0.993      0.993      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20       2.9G     0.7083     0.4523     0.8997          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.0it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.3s\n",
            "                   all        153        153      0.991       0.98      0.993      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      2.91G     0.6779     0.4258     0.8849          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.0it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.8it/s 2.7s\n",
            "                   all        153        153      0.989      0.993      0.991      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      2.93G     0.6613     0.4123     0.8848          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.2it/s 23.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.3it/s 2.2s\n",
            "                   all        153        153      0.993       0.98      0.993      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      2.95G     0.6458     0.4037     0.8837          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.1it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.4it/s 2.1s\n",
            "                   all        153        153      0.992       0.98      0.994      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      2.97G     0.6204     0.3719     0.8572          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.1it/s 23.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        153        153      0.987          1      0.994      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      2.98G     0.5978     0.3613     0.8545          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.2it/s 22.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.4it/s 2.1s\n",
            "                   all        153        153      0.994      0.999      0.993      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20         3G     0.5912     0.3441     0.8486          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.2it/s 23.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.8it/s 1.8s\n",
            "                   all        153        153      0.993          1      0.994       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      3.02G     0.5771     0.3401     0.8527          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 96/96 4.3it/s 22.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.5it/s 2.0s\n",
            "                   all        153        153      0.992          1      0.994      0.888\n",
            "\n",
            "20 epochs completed in 0.153 hours.\n",
            "Optimizer stripped from /content/runs_lp/single_run/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_lp/single_run/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_lp/single_run/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.3it/s 2.2s\n",
            "                   all        153        153      0.992          1      0.994      0.888\n",
            "Speed: 0.3ms preprocess, 3.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/single_run\u001b[0m\n",
            "Training completed.\n",
            "Run directory: /content/runs_lp/single_run\n"
          ]
        }
      ],
      "source": [
        "# Choose a YOLOv8 model (n: nano, s: small)\n",
        "model_name = \"yolov8n.pt\"\n",
        "epochs = 20\n",
        "imgsz = 640\n",
        "\n",
        "model = YOLO(model_name)\n",
        "results = model.train(data=data_yaml_path, epochs=epochs, imgsz=imgsz, project=\"runs_lp\", name=\"single_run\", exist_ok=True, verbose=True)\n",
        "\n",
        "print(\"Training completed.\")\n",
        "print(\"Run directory:\", results.save_dir if hasattr(results, \"save_dir\") else \"See 'runs_lp/detect/single_run'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b630fece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b630fece",
        "outputId": "892b8248-f45d-41c1-f293-bf9d59cd576a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1261.4Â±1102.3 MB/s, size: 170.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/labels/val.cache... 153 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 153/153 326.7Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.5it/s 2.8s\n",
            "                   all        153        153      0.993          1      0.994      0.886\n",
            "Speed: 2.7ms preprocess, 5.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/single_run_val\u001b[0m\n",
            "Metrics: {'metrics/precision(B)': 0.9925177318954409, 'metrics/recall(B)': 1.0, 'metrics/mAP50(B)': 0.9944155844155843, 'metrics/mAP50-95(B)': 0.8860900400980102, 'fitness': 0.8860900400980102}\n",
            "Results saved to \u001b[1m/content/runs_lp/predictions/vis\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/predictions/vis\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/predictions/vis\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/predictions/vis\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/predictions/vis\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/predictions/vis\u001b[0m\n",
            "Saved example predictions to: runs_lp/predictions/vis\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Validation\n",
        "val_results = model.val(data=data_yaml_path, imgsz=imgsz, split=\"val\", project=\"runs_lp\", name=\"single_run_val\", exist_ok=True, verbose=True)\n",
        "\n",
        "# Extract metrics\n",
        "metrics = val_results.results_dict if hasattr(val_results, \"results_dict\") else {}\n",
        "print(\"Metrics:\", metrics)\n",
        "\n",
        "# Visualize predictions on a few images from the val set\n",
        "val_images = glob.glob(os.path.join(images_dir, \"val\", \"*.*\"))\n",
        "sample_images = random.sample(val_images, min(6, len(val_images)))\n",
        "\n",
        "pred_dir = os.path.join(\"runs_lp\", \"predictions\")\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "for img_path in sample_images:\n",
        "    pred = model.predict(source=img_path, save=True, project=pred_dir, name=\"vis\", exist_ok=True, verbose=False)\n",
        "\n",
        "print(\"Saved example predictions to:\", os.path.join(pred_dir, \"vis\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2de5f31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c2de5f31",
        "outputId": "774ce134-2a12-4f34-c50a-aad9b6cd9d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labeled images for CV: 1679\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/license_plate_data/cv_folds/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cv_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_lp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_lp/cv_fold_0, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1390.5Â±952.6 MB/s, size: 139.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_0/labels/train... 1343 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1343/1343 2.5Kit/s 0.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_0/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 591.0Â±366.2 MB/s, size: 48.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_0/labels/val... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 927.6it/s 0.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_0/labels/val.cache\n",
            "Plotting labels to /content/runs_lp/cv_fold_0/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_lp/cv_fold_0\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      2.15G          1      2.415      1.068         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.5it/s 24.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.5s\n",
            "                   all        336        336      0.948      0.869      0.954      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      2.72G     0.9366       1.42      1.001         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.4it/s 3.2s\n",
            "                   all        336        336      0.972      0.915      0.966      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      2.72G     0.9302      1.061     0.9918         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.1it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.4it/s 3.2s\n",
            "                   all        336        336      0.953      0.923      0.972      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      2.72G     0.8952     0.8563     0.9872         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.8it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.6it/s 3.0s\n",
            "                   all        336        336       0.93      0.917      0.968      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      2.72G     0.8509     0.7144     0.9546         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.2it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.1it/s 3.5s\n",
            "                   all        336        336      0.961       0.96      0.979       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      2.72G     0.8008     0.6251     0.9416         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.3it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.7it/s 4.1s\n",
            "                   all        336        336      0.967       0.97      0.983      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      2.72G      0.755     0.5627     0.9115         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.3it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.9it/s 3.7s\n",
            "                   all        336        336      0.978      0.982      0.991      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      2.74G      0.691     0.5181     0.8881         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.2it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.8it/s 2.9s\n",
            "                   all        336        336       0.99      0.976      0.988      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      2.76G     0.6703     0.4755     0.8796         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.7it/s 3.0s\n",
            "                   all        336        336      0.988      0.982      0.991      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      2.78G     0.6438     0.4349     0.8715         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.6it/s 3.0s\n",
            "                   all        336        336      0.982      0.988      0.992      0.841\n",
            "\n",
            "10 epochs completed in 0.069 hours.\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_0/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_0/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_lp/cv_fold_0/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.3it/s 3.3s\n",
            "                   all        336        336      0.982      0.988      0.992      0.841\n",
            "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_0\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1771.6Â±1397.8 MB/s, size: 95.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_0/labels/val.cache... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 756.1Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 5.2it/s 4.0s\n",
            "                   all        336        336      0.979      0.988      0.992      0.835\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_0_val\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/license_plate_data/cv_folds/fold_1/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cv_fold_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_lp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_lp/cv_fold_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1576.3Â±899.1 MB/s, size: 101.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_1/labels/train... 1343 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1343/1343 2.3Kit/s 0.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_1/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 506.7Â±124.0 MB/s, size: 68.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_1/labels/val... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 751.7it/s 0.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_1/labels/val.cache\n",
            "Plotting labels to /content/runs_lp/cv_fold_1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_lp/cv_fold_1\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      2.15G      1.007      2.413      1.037         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.4it/s 24.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.7it/s 2.9s\n",
            "                   all        336        336      0.975      0.902      0.971      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      2.72G     0.9362      1.423     0.9837         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.4s\n",
            "                   all        336        336      0.918      0.936       0.96      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      2.72G      0.938      1.061     0.9861         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.1it/s 20.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.6it/s 4.2s\n",
            "                   all        336        336       0.96      0.929      0.968      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      2.72G     0.8732     0.8391     0.9651         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.1it/s 20.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.2it/s 4.9s\n",
            "                   all        336        336       0.96      0.949      0.987      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      2.72G     0.8602     0.7091     0.9464         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 4.1it/s 2.7s\n",
            "                   all        336        336      0.991      0.964      0.991      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      2.74G     0.7964     0.6278     0.9237         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 4.2it/s 2.6s\n",
            "                   all        336        336      0.987       0.97      0.994      0.786\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      2.76G     0.7553     0.5529     0.9089         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.1s\n",
            "                   all        336        336      0.991      0.976      0.992      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      2.78G     0.7189     0.5125     0.8854         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 4.2it/s 2.6s\n",
            "                   all        336        336      0.991      0.979      0.994      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      2.79G     0.6755     0.4867     0.8759         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.8it/s 21.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 4.4it/s 2.5s\n",
            "                   all        336        336      0.984      0.985      0.994      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      2.81G     0.6318     0.4399     0.8555         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.6it/s 3.0s\n",
            "                   all        336        336      0.991      0.994      0.995      0.852\n",
            "\n",
            "10 epochs completed in 0.070 hours.\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_1/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_1/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_lp/cv_fold_1/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.2s\n",
            "                   all        336        336      0.991      0.994      0.995      0.852\n",
            "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_1\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1211.7Â±881.7 MB/s, size: 77.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_1/labels/val.cache... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 574.0Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 4.6it/s 4.5s\n",
            "                   all        336        336      0.988      0.994      0.995      0.858\n",
            "Speed: 1.7ms preprocess, 3.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_1_val\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/license_plate_data/cv_folds/fold_2/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cv_fold_2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_lp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_lp/cv_fold_2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1001.2Â±513.6 MB/s, size: 38.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_2/labels/train... 1343 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1343/1343 2.3Kit/s 0.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_2/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 450.5Â±246.5 MB/s, size: 146.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_2/labels/val... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 1.1Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_2/labels/val.cache\n",
            "Plotting labels to /content/runs_lp/cv_fold_2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_lp/cv_fold_2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      2.19G     0.9899      2.374      1.034         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.4it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.5it/s 4.5s\n",
            "                   all        336        336       0.99      0.874      0.974      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      2.61G     0.9698      1.422     0.9954         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.1it/s 20.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.9it/s 3.8s\n",
            "                   all        336        336      0.946       0.94      0.973       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      2.61G     0.9385      1.066     0.9923         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.1it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.9it/s 2.8s\n",
            "                   all        336        336       0.96      0.868      0.954      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      2.61G     0.8889     0.8468     0.9752         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.4it/s 3.3s\n",
            "                   all        336        336      0.972      0.964      0.988      0.783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      2.61G     0.8394     0.6993     0.9554         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.4it/s 3.3s\n",
            "                   all        336        336      0.962      0.961      0.989      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      2.61G     0.7933     0.6147     0.9183         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.3it/s 3.3s\n",
            "                   all        336        336      0.981      0.952      0.989        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      2.62G     0.7576     0.5612     0.9031         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.2s\n",
            "                   all        336        336      0.988      0.982      0.994      0.816\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      2.63G     0.7193     0.5213     0.8901         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.6it/s 3.1s\n",
            "                   all        336        336      0.991      0.982      0.994      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      2.65G     0.6841     0.4859     0.8793         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.4s\n",
            "                   all        336        336      0.994      0.984      0.995      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      2.67G     0.6654     0.4529     0.8676         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.2it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.6it/s 4.3s\n",
            "                   all        336        336      0.988      0.993      0.995      0.854\n",
            "\n",
            "10 epochs completed in 0.071 hours.\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_lp/cv_fold_2/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.4s\n",
            "                   all        336        336      0.988      0.993      0.995      0.855\n",
            "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_2\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1814.7Â±1441.4 MB/s, size: 101.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_2/labels/val.cache... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 709.3Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 4.1it/s 5.1s\n",
            "                   all        336        336      0.991      0.993      0.995      0.858\n",
            "Speed: 2.1ms preprocess, 3.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_2_val\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/license_plate_data/cv_folds/fold_3/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cv_fold_3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_lp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_lp/cv_fold_3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1363.9Â±956.6 MB/s, size: 122.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_3/labels/train... 1343 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1343/1343 2.3Kit/s 0.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_3/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 348.4Â±167.4 MB/s, size: 66.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_3/labels/val... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 986.1it/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_3/labels/val.cache\n",
            "Plotting labels to /content/runs_lp/cv_fold_3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_lp/cv_fold_3\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      2.21G      1.026      2.424      1.018         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.4it/s 24.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.7it/s 4.0s\n",
            "                   all        336        336      0.926      0.917      0.961      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      2.78G     0.9606      1.436     0.9659         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.2s\n",
            "                   all        336        336       0.96      0.941      0.978      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      2.78G     0.9743      1.095     0.9903         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.4it/s 3.2s\n",
            "                   all        336        336      0.932      0.955      0.965      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      2.78G     0.9096     0.8669     0.9699         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.1s\n",
            "                   all        336        336      0.979      0.955      0.986      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      2.78G     0.8261     0.7015     0.9281         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.8it/s 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.9it/s 2.9s\n",
            "                   all        336        336      0.987      0.964      0.992      0.768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      2.78G     0.7934     0.6217     0.9147         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.8it/s 2.9s\n",
            "                   all        336        336      0.962       0.98      0.992      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      2.78G     0.7503     0.5538     0.8987         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.3it/s 3.4s\n",
            "                   all        336        336      0.971      0.994      0.993      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      2.78G     0.7389     0.5197     0.8961         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.2s\n",
            "                   all        336        336      0.976      0.981      0.992      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10       2.8G     0.6744      0.471     0.8697         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.5it/s 4.4s\n",
            "                   all        336        336      0.982          1      0.994      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      2.82G      0.652     0.4465      0.872         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.1it/s 20.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.9it/s 3.8s\n",
            "                   all        336        336      0.985      0.988      0.993      0.849\n",
            "\n",
            "10 epochs completed in 0.071 hours.\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_3/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_3/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_lp/cv_fold_3/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.4s\n",
            "                   all        336        336      0.985      0.988      0.993      0.848\n",
            "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_3\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1693.9Â±1002.3 MB/s, size: 107.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_3/labels/val.cache... 336 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 336/336 717.2Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 4.1it/s 5.2s\n",
            "                   all        336        336      0.985      0.988      0.993       0.85\n",
            "Speed: 2.2ms preprocess, 4.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_3_val\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/license_plate_data/cv_folds/fold_4/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cv_fold_4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_lp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_lp/cv_fold_4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1494.8Â±956.7 MB/s, size: 92.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_4/labels/train... 1344 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1344/1344 2.3Kit/s 0.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_4/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 337.1Â±196.1 MB/s, size: 91.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_4/labels/val... 335 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 335/335 1.0Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/license_plate_data/cv_folds/fold_4/labels/val.cache\n",
            "Plotting labels to /content/runs_lp/cv_fold_4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_lp/cv_fold_4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      2.22G     0.9753      2.364      1.011         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.3it/s 25.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.6it/s 4.2s\n",
            "                   all        335        335      0.973      0.753      0.946      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      2.64G     0.9505      1.413     0.9815         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.4s\n",
            "                   all        335        335      0.942      0.914      0.969      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      2.64G     0.9671      1.079      1.009         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.4it/s 3.2s\n",
            "                   all        335        335      0.955      0.955      0.981      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      2.64G     0.8957     0.8453     0.9787         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.8it/s 21.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.1s\n",
            "                   all        335        335      0.976       0.97      0.992      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      2.64G     0.8439     0.6965      0.948         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.5it/s 3.1s\n",
            "                   all        335        335      0.985      0.961      0.992      0.803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      2.64G     0.8032     0.6312     0.9302         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.8it/s 21.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.6it/s 3.0s\n",
            "                   all        335        335      0.979      0.983      0.993      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      2.64G     0.7744     0.5766     0.9218         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.9it/s 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.3it/s 3.3s\n",
            "                   all        335        335      0.979      0.987      0.994      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      2.64G     0.7231     0.5266     0.9057         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 3.8it/s 21.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.0it/s 3.6s\n",
            "                   all        335        335      0.985      0.996      0.993      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      2.65G     0.6779     0.4743     0.8802         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.7it/s 4.1s\n",
            "                   all        335        335      0.982          1      0.995      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      2.67G     0.6399      0.446     0.8618         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 84/84 4.0it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 2.8it/s 3.9s\n",
            "                   all        335        335      0.998      0.985      0.995      0.858\n",
            "\n",
            "10 epochs completed in 0.072 hours.\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_4/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_lp/cv_fold_4/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_lp/cv_fold_4/weights/best.pt...\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 11/11 3.2it/s 3.4s\n",
            "                   all        335        335      0.998      0.985      0.995      0.857\n",
            "Speed: 0.3ms preprocess, 2.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_4\u001b[0m\n",
            "Ultralytics 8.3.227 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1160.8Â±806.4 MB/s, size: 45.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/license_plate_data/cv_folds/fold_4/labels/val.cache... 335 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 335/335 665.6Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 21/21 4.3it/s 4.9s\n",
            "                   all        335        335          1      0.987      0.995      0.856\n",
            "Speed: 2.2ms preprocess, 3.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_lp/cv_fold_4_val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
              "0              0.979092           0.988095          0.992026   \n",
              "1              0.987505           0.994048          0.994822   \n",
              "2              0.991091           0.993216          0.994669   \n",
              "3              0.984817           0.988095          0.992783   \n",
              "4              1.000000           0.986720          0.994881   \n",
              "\n",
              "   metrics/mAP50-95(B)   fitness  fold  \n",
              "0             0.835099  0.835099     0  \n",
              "1             0.857772  0.857772     1  \n",
              "2             0.857991  0.857991     2  \n",
              "3             0.849777  0.849777     3  \n",
              "4             0.856350  0.856350     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73b8b5cf-e05b-4a3a-8c56-d988eed61011\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metrics/precision(B)</th>\n",
              "      <th>metrics/recall(B)</th>\n",
              "      <th>metrics/mAP50(B)</th>\n",
              "      <th>metrics/mAP50-95(B)</th>\n",
              "      <th>fitness</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.979092</td>\n",
              "      <td>0.988095</td>\n",
              "      <td>0.992026</td>\n",
              "      <td>0.835099</td>\n",
              "      <td>0.835099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.987505</td>\n",
              "      <td>0.994048</td>\n",
              "      <td>0.994822</td>\n",
              "      <td>0.857772</td>\n",
              "      <td>0.857772</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.991091</td>\n",
              "      <td>0.993216</td>\n",
              "      <td>0.994669</td>\n",
              "      <td>0.857991</td>\n",
              "      <td>0.857991</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.984817</td>\n",
              "      <td>0.988095</td>\n",
              "      <td>0.992783</td>\n",
              "      <td>0.849777</td>\n",
              "      <td>0.849777</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.986720</td>\n",
              "      <td>0.994881</td>\n",
              "      <td>0.856350</td>\n",
              "      <td>0.856350</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73b8b5cf-e05b-4a3a-8c56-d988eed61011')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73b8b5cf-e05b-4a3a-8c56-d988eed61011 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73b8b5cf-e05b-4a3a-8c56-d988eed61011');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-82968db0-044c-4635-bfab-c0a2562e7de7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82968db0-044c-4635-bfab-c0a2562e7de7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-82968db0-044c-4635-bfab-c0a2562e7de7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6bfa0861-516b-4452-8f82-0da33120b94d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cv_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6bfa0861-516b-4452-8f82-0da33120b94d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cv_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cv_df",
              "summary": "{\n  \"name\": \"cv_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"metrics/precision(B)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007778644624376093,\n        \"min\": 0.9790917628316741,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9875048424601964,\n          1.0,\n          0.9910905235229001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metrics/recall(B)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0033442202851204166,\n        \"min\": 0.9867202921290558,\n        \"max\": 0.9940476190476191,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9940476190476191,\n          0.9867202921290558,\n          0.9880952380952381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metrics/mAP50(B)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013363765128703144,\n        \"min\": 0.9920256455621318,\n        \"max\": 0.9948809523809524,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9948215967446737,\n          0.9948809523809524,\n          0.9946686872470641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metrics/mAP50-95(B)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009707007730528504,\n        \"min\": 0.8350989741068103,\n        \"max\": 0.8579912909410172,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8577718533171123,\n          0.8563496942335357,\n          0.8579912909410172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fitness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009707007730528504,\n        \"min\": 0.8350989741068103,\n        \"max\": 0.8579912909410172,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8577718533171123,\n          0.8563496942335357,\n          0.8579912909410172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "# Build a unified list of (image, label) from train+val\n",
        "trainval_imgs = glob.glob(os.path.join(images_dir, \"train\", \"*.*\")) + glob.glob(os.path.join(images_dir, \"val\", \"*.*\"))\n",
        "random.shuffle(trainval_imgs)\n",
        "\n",
        "def yolo_pair(img_path):\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(labels_dir, \"train\", base + \".txt\")\n",
        "    if not os.path.exists(label_path):\n",
        "        label_path = os.path.join(labels_dir, \"val\", base + \".txt\")\n",
        "    return img_path, (label_path if os.path.exists(label_path) else None)\n",
        "\n",
        "pairs = [yolo_pair(p) for p in trainval_imgs]\n",
        "pairs = [p for p in pairs if p[1] is not None]  # keep only those with labels\n",
        "\n",
        "print(f\"Total labeled images for CV: {len(pairs)}\")\n",
        "\n",
        "# Create temp fold directories under work_dir/cv_folds\n",
        "cv_root = os.path.join(work_dir, \"cv_folds\")\n",
        "os.makedirs(cv_root, exist_ok=True)\n",
        "\n",
        "def write_list_to_file(paths, out_txt):\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        for p in paths:\n",
        "            f.write(p + \"\\n\")\n",
        "\n",
        "# Helper to copy images/labels into a YOLO structure\n",
        "def build_yolo_split(dest_root, train_list, val_list):\n",
        "    for subset, subset_list in [(\"train\", train_list), (\"val\", val_list)]:\n",
        "        img_dest = os.path.join(dest_root, \"images\", subset)\n",
        "        lbl_dest = os.path.join(dest_root, \"labels\", subset)\n",
        "        os.makedirs(img_dest, exist_ok=True); os.makedirs(lbl_dest, exist_ok=True)\n",
        "        for img in subset_list:\n",
        "            base = os.path.splitext(os.path.basename(img))[0]\n",
        "            # image\n",
        "            shutil.copy2(img, os.path.join(img_dest, os.path.basename(img)))\n",
        "            # label (search in train/val labels)\n",
        "            lbl = os.path.join(labels_dir, \"train\", base + \".txt\")\n",
        "            if not os.path.exists(lbl):\n",
        "                lbl = os.path.join(labels_dir, \"val\", base + \".txt\")\n",
        "            if os.path.exists(lbl):\n",
        "                shutil.copy2(lbl, os.path.join(lbl_dest, os.path.basename(lbl)))\n",
        "\n",
        "def run_fold(fold_idx, train_imgs, val_imgs, epochs_per_fold=10):\n",
        "    fold_root = os.path.join(cv_root, f\"fold_{fold_idx}\")\n",
        "    if os.path.exists(fold_root):\n",
        "        shutil.rmtree(fold_root)\n",
        "    os.makedirs(fold_root, exist_ok=True)\n",
        "    build_yolo_split(fold_root, train_imgs, val_imgs)\n",
        "    # write data.yaml for the fold\n",
        "    fold_yaml = os.path.join(fold_root, \"data.yaml\")\n",
        "    fold_cfg = {\n",
        "        \"train\": os.path.join(fold_root, \"images\", \"train\"),\n",
        "        \"val\":   os.path.join(fold_root, \"images\", \"val\"),\n",
        "        \"nc\":    1,\n",
        "        \"names\": [\"license_plate\"]\n",
        "    }\n",
        "    with open(fold_yaml, \"w\") as f:\n",
        "        yaml.safe_dump(fold_cfg, f, sort_keys=False)\n",
        "    # train\n",
        "    fold_model = YOLO(model_name)\n",
        "    fold_results = fold_model.train(data=fold_yaml, epochs=epochs_per_fold, imgsz=imgsz, project=\"runs_lp\", name=f\"cv_fold_{fold_idx}\", exist_ok=True, verbose=True)\n",
        "    # validate\n",
        "    fold_val = fold_model.val(data=fold_yaml, imgsz=imgsz, split=\"val\", project=\"runs_lp\", name=f\"cv_fold_{fold_idx}_val\", exist_ok=True, verbose=True)\n",
        "    # collect key metrics\n",
        "    mdict = fold_val.results_dict if hasattr(fold_val, \"results_dict\") else {}\n",
        "    return mdict\n",
        "\n",
        "# 5-Fold split\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "metrics_list = []\n",
        "imgs_only = [p[0] for p in pairs]\n",
        "\n",
        "fold_num = 0\n",
        "for train_idx, val_idx in kf.split(imgs_only):\n",
        "    train_imgs = [imgs_only[i] for i in train_idx]\n",
        "    val_imgs   = [imgs_only[i] for i in val_idx]\n",
        "    mdict = run_fold(fold_num, train_imgs, val_imgs, epochs_per_fold=10)  # adjust epochs for time\n",
        "    mdict[\"fold\"] = fold_num\n",
        "    metrics_list.append(mdict)\n",
        "    fold_num += 1\n",
        "\n",
        "cv_df = pd.DataFrame(metrics_list)\n",
        "cv_csv = os.path.join(work_dir, \"cv_metrics.csv\")\n",
        "cv_df.to_csv(cv_csv, index=False)\n",
        "cv_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403c42d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "403c42d5",
        "outputId": "56aeb2bf-a20b-495b-e71c-19c1a39ae4c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          mean       std\n",
              "metrics/precision(B)  0.988501  0.007779\n",
              "metrics/recall(B)     0.990035  0.003344\n",
              "metrics/mAP50(B)      0.993836  0.001336\n",
              "metrics/mAP50-95(B)   0.851398  0.009707"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7beaba9e-f56b-43be-bee5-35f8f1fa32cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>metrics/precision(B)</th>\n",
              "      <td>0.988501</td>\n",
              "      <td>0.007779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics/recall(B)</th>\n",
              "      <td>0.990035</td>\n",
              "      <td>0.003344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics/mAP50(B)</th>\n",
              "      <td>0.993836</td>\n",
              "      <td>0.001336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics/mAP50-95(B)</th>\n",
              "      <td>0.851398</td>\n",
              "      <td>0.009707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7beaba9e-f56b-43be-bee5-35f8f1fa32cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7beaba9e-f56b-43be-bee5-35f8f1fa32cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7beaba9e-f56b-43be-bee5-35f8f1fa32cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a75277ff-44ab-4111-81ee-f97c09b38081\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a75277ff-44ab-4111-81ee-f97c09b38081')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a75277ff-44ab-4111-81ee-f97c09b38081 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3ac49b55-4b93-4c4d-91c6-20c57a7c50ad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3ac49b55-4b93-4c4d-91c6-20c57a7c50ad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary_df",
              "summary": "{\n  \"name\": \"summary_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06973251933177647,\n        \"min\": 0.8513976796527402,\n        \"max\": 0.9938359078211662,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9900349630974421,\n          0.8513976796527402,\n          0.9885008614354849\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0038672717513073443,\n        \"min\": 0.0013363765128703144,\n        \"max\": 0.009707007730528504,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0033442202851204166,\n          0.009707007730528504,\n          0.007778644624376093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved CV summary: /content/license_plate_data/cv_summary.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def pretty_summary(df):\n",
        "    cols = [c for c in df.columns if any(k in c for k in [\"precision\",\"recall\",\"map\",\"mAP\",\"mp\",\"mr\"])]\n",
        "    if not cols:\n",
        "        print(\"Columns:\", df.columns.tolist())\n",
        "        raise RuntimeError(\"No metric columns detected; check fold results.\")\n",
        "    summary = df[cols].agg([\"mean\",\"std\"]).T\n",
        "    return summary\n",
        "\n",
        "summary_df = pretty_summary(cv_df)\n",
        "display(summary_df)\n",
        "\n",
        "# Save a formatted CSV for your article\n",
        "summary_path = os.path.join(work_dir, \"cv_summary.csv\")\n",
        "summary_df.to_csv(summary_path)\n",
        "print(\"Saved CV summary:\", summary_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fffa162a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fffa162a",
        "outputId": "b104d197-42c8-465a-896c-a47e18ca96eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "Results saved to \u001b[1m/content/runs_lp/demo_vis/pred\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/demo_vis/pred\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/demo_vis/pred\u001b[0m\n",
            "WARNING âš ï¸ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "Results saved to \u001b[1m/content/runs_lp/demo_vis/pred\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/demo_vis/pred\u001b[0m\n",
            "Results saved to \u001b[1m/content/runs_lp/demo_vis/pred\u001b[0m\n",
            "Demo predictions saved to: runs_lp/demo_vis/pred\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load best weights from single run\n",
        "best_weights = sorted(glob.glob(os.path.join(\"runs_lp\",\"detect\",\"single_run\",\"weights\",\"best.pt\")), key=lambda p: os.path.getmtime(p))\n",
        "if len(best_weights)==0:\n",
        "    # ultralytics uses project/task folder naming; fall back search\n",
        "    best_weights = glob.glob(\"runs_lp/**/weights/best.pt\", recursive=True)\n",
        "\n",
        "assert len(best_weights)>0, \"Best weights not found. Check training run directories.\"\n",
        "best_w = best_weights[-1]\n",
        "\n",
        "best_model = YOLO(best_w)\n",
        "\n",
        "test_images = glob.glob(os.path.join(images_dir, \"test\", \"*.*\"))\n",
        "sample_test = random.sample(test_images, min(6, len(test_images))) if len(test_images)>0 else random.sample(glob.glob(os.path.join(images_dir,\"val\",\"*.*\")), 6)\n",
        "\n",
        "out_demo = os.path.join(\"runs_lp\",\"demo_vis\")\n",
        "for img_path in sample_test:\n",
        "    best_model.predict(source=img_path, save=True, project=out_demo, name=\"pred\", exist_ok=True, verbose=False)\n",
        "\n",
        "print(\"Demo predictions saved to:\", os.path.join(out_demo, \"pred\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*IF THERE ANY ISSUES WITH FILES AFTER DOWNLOADING DATASET*\n"
      ],
      "metadata": {
        "id": "PHXIZme87fCn"
      },
      "id": "PHXIZme87fCn"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Auto-fix data.yaml: find the real images/ and rewrite paths ---\n",
        "import os, glob, yaml, shutil\n",
        "\n",
        "# 1) ĞĞ°Ğ¹Ğ´Ñ‘Ğ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ (Ñ‚Ğ°Ğ¼ Ğ³Ğ´Ğµ Ñ€Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²Ğ°Ğ»Ğ¸)\n",
        "candidates = [\n",
        "    \"/kaggle/working/license_plate_data\",\n",
        "    \"/content/license_plate_data\",\n",
        "    \"./license_plate_data\",\n",
        "    \"/content\",  # Ğ½Ğ° Ğ²ÑÑĞºĞ¸Ğ¹ ÑĞ»ÑƒÑ‡Ğ°Ğ¹ Ğ¸Ñ‰ĞµĞ¼ Ğ³Ğ»ÑƒĞ±Ğ¶Ğµ\n",
        "]\n",
        "work_dir = next((p for p in candidates if os.path.exists(p)), None)\n",
        "if work_dir is None:\n",
        "    raise FileNotFoundError(\"ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ work_dir. Ğ£ĞºĞ°Ğ¶Ğ¸ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‡ĞµĞ¹ Ğ¿Ğ°Ğ¿ĞºĞµ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸.\")\n",
        "\n",
        "print(\"work_dir:\", work_dir)\n",
        "\n",
        "# 2) ĞĞ°Ğ¹Ğ´Ñ‘Ğ¼ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ images (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ train Ğ¸ val/valid)\n",
        "def find_images_root(base):\n",
        "    for root, dirs, files in os.walk(base):\n",
        "        if os.path.basename(root).lower() == \"images\":\n",
        "            subs = set([d.lower() for d in dirs])\n",
        "            if (\"train\" in subs) and ((\"val\" in subs) or (\"valid\" in subs)):\n",
        "                return root\n",
        "    return None\n",
        "\n",
        "images_dir = find_images_root(work_dir)\n",
        "if images_dir is None:\n",
        "    # Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°ÑÑ‚ Ğ½Ğ° ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ³Ğ»ÑƒĞ±Ğ¶Ğµ â€” Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾Ğ¹ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¿ĞºĞ¸ Ñ Ñ‚ĞµĞ¼ Ğ¶Ğµ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼\n",
        "    nested = os.path.join(work_dir, \"license_plate_data\")\n",
        "    if os.path.exists(nested):\n",
        "        images_dir = find_images_root(nested)\n",
        "\n",
        "if images_dir is None:\n",
        "    raise RuntimeError(\"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ°Ğ¿ĞºÑƒ 'images' Ñ Ğ¿Ğ¾Ğ´ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ°Ğ¼Ğ¸ train/val. ĞŸĞ¾ĞºĞ°Ğ¶Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ work_dir.\")\n",
        "\n",
        "print(\"images_dir:\", images_dir)\n",
        "\n",
        "# 3) ĞŸÑ€Ğ¸Ğ²ĞµĞ´Ñ‘Ğ¼ 'valid' -> 'val' Ğ¸ Ñ‚Ğ¾ Ğ¶Ğµ Ğ´Ğ»Ñ labels\n",
        "labels_dir = os.path.join(os.path.dirname(images_dir), \"labels\")\n",
        "valid_img = os.path.join(images_dir, \"valid\")\n",
        "valid_lbl = os.path.join(labels_dir, \"valid\")\n",
        "val_img  = os.path.join(images_dir, \"val\")\n",
        "val_lbl  = os.path.join(labels_dir, \"val\")\n",
        "\n",
        "if os.path.isdir(valid_img) and not os.path.isdir(val_img):\n",
        "    os.rename(valid_img, val_img)\n",
        "    print(\"Renamed images/valid -> images/val\")\n",
        "if os.path.isdir(valid_lbl) and not os.path.isdir(val_lbl):\n",
        "    os.rename(valid_lbl, val_lbl)\n",
        "    print(\"Renamed labels/valid -> labels/val\")\n",
        "\n",
        "# 4) Ğ£Ğ±ĞµĞ´Ğ¸Ğ¼ÑÑ, Ñ‡Ñ‚Ğ¾ train/val ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‚ Ğ¸ Ğ½ĞµĞ¿ÑƒÑÑ‚Ñ‹Ğµ\n",
        "def has_images(p):\n",
        "    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\")\n",
        "    return any(fn.lower().endswith(exts) for fn in os.listdir(p)) if os.path.isdir(p) else False\n",
        "\n",
        "assert os.path.isdir(os.path.join(images_dir, \"train\")), \"ĞĞµÑ‚ Ğ¿Ğ°Ğ¿ĞºĞ¸ images/train\"\n",
        "assert os.path.isdir(os.path.join(images_dir, \"val\")),   \"ĞĞµÑ‚ Ğ¿Ğ°Ğ¿ĞºĞ¸ images/val\"\n",
        "\n",
        "# 5) Ğ•ÑĞ»Ğ¸ test Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ´Ğ¸Ğ¼ Ğ¸Ğ· Ñ‡Ğ°ÑÑ‚Ğ¸ val (Ğ½ĞµĞ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾, Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾)\n",
        "test_img = os.path.join(images_dir, \"test\")\n",
        "test_lbl = os.path.join(labels_dir, \"test\")\n",
        "if not os.path.isdir(test_img):\n",
        "    os.makedirs(test_img, exist_ok=True)\n",
        "    os.makedirs(test_lbl, exist_ok=True)\n",
        "    # Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼ â€” Ultralytics Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ train/val; test Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ñ‚Ğ²Ğ¾Ğ¸Ñ… Ğ´ĞµĞ¼Ğ¾-Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹\n",
        "    print(\"Created empty images/test and labels/test\")\n",
        "\n",
        "# 6) ĞŸĞµÑ€ĞµĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ data.yaml Ñ€ÑĞ´Ğ¾Ğ¼ Ñ work_dir (Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ğ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ data_yaml_path)\n",
        "data_yaml_path = os.path.join(work_dir, \"data.yaml\")\n",
        "cfg = {\n",
        "    \"train\": os.path.join(images_dir, \"train\"),\n",
        "    \"val\":   os.path.join(images_dir, \"val\"),\n",
        "    \"test\":  test_img if os.path.isdir(test_img) else os.path.join(images_dir, \"val\"),\n",
        "    \"nc\":    1,\n",
        "    \"names\": [\"license_plate\"],\n",
        "}\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(\"Rewrote data.yaml:\", data_yaml_path)\n",
        "print(open(data_yaml_path).read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H08Cpxok1iiA",
        "outputId": "d45fd264-9d5a-44fd-9e59-842f53f84944"
      },
      "id": "H08Cpxok1iiA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work_dir: /content/license_plate_data\n",
            "images_dir: /content/license_plate_data/images\n",
            "âœ… Rewrote data.yaml: /content/license_plate_data/data.yaml\n",
            "train: /content/license_plate_data/images/train\n",
            "val: /content/license_plate_data/images/val\n",
            "test: /content/license_plate_data/images/test\n",
            "nc: 1\n",
            "names:\n",
            "- license_plate\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}